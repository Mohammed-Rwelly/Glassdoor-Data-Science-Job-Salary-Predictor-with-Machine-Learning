{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a74fc35",
   "metadata": {},
   "source": [
    "#### Import libraries do we need it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583bafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException ,TimeoutException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "#from webdriver_manager.core.utils import ChromeType\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime,timedelta\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9acb3",
   "metadata": {},
   "source": [
    "#### We want to create a function get_jobs for  scripting will exactly do the following. Search for a given keyword, click on each job all on the job listings all the way down, click on different tabs in the job description panel, scrape all the data. When it reaches the end of the list, it will go to the next page of results and keep doing the same thing, until a target number of jobs scraped. The final result will simulate Google chrom and the ending will store the result in database using amazone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41dc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs,path):\n",
    "    jobs_for_country = []\n",
    "    global jobs_for_countries\n",
    "    jobs_for_countries = []\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    \n",
    "    for key in range(len(keyword)):\n",
    "        jobs_for_keyword=[]\n",
    "        url='https://www.glassdoor.com/Search/results.htm?keyword={}&locT'.format(keyword[key].replace('_','%20'))\n",
    "        time.sleep(5)\n",
    "        driver.get(url)\n",
    "        # Let the page load. Change this number based on your internet speed.\n",
    "        # Maybe add extra sleeping at the steps you need for more loading time. \n",
    "        time.sleep(3)\n",
    "        #click on button search depends on job_title and city \n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//span[@class=\"SVGInline d-flex white\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "        #after loding the page we are clicking on \"see all the jobs \" button \n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//span[@class=\"SVGInline css-1mgba7 css-1hjgaef\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(5)  \n",
    "        while len(jobs_for_keyword) < num_jobs: \n",
    "           job_buttons = driver.find_elements(By.XPATH,\"//*[@id='MainCol']/div[1]/ul/li\")\n",
    "           # Going through each job url in this page\n",
    "           job_buttons_href = driver.find_elements(By.XPATH,'//*[@id=\"MainCol\"]/div[1]/ul/li/div[2]/a')\n",
    "           \n",
    "           # Initialize all parameters numeric to zero and quetation \" \" with a string parameter ,because if we does not initialized we get an error local variable  referenced before assignmen\n",
    "           job_id,salary_estimate,founded=0,0,0\n",
    "           current_date,company_name,job_type,job_url,job_description_full,Posted_Date,job_title,size,sector,type_of_ownership,industry,revenue,city=\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
    "           try:\n",
    "            number_of_all_page=driver.find_element(By.CLASS_NAME, \"paginationFooter\").text\n",
    "            print(\"Now we in {} \".format(number_of_all_page)) \n",
    "           except NoSuchElementException:\n",
    "            pass  \n",
    "           #for job in range(len(job_buttons)):\n",
    "           for job_button in job_buttons:\n",
    "               print(\"Progress: {}\".format(\"\" + str(len(jobs_for_keyword)) + \"/\" + str(num_jobs)))\n",
    "               if len(jobs_for_keyword) >= num_jobs:\n",
    "                   # When the number of jobs collected has reached the number we set.\n",
    "                   print(\"br\")\n",
    "                   break\n",
    "               try:\n",
    "                   job_button.click()\n",
    "               except:\n",
    "                   pass\n",
    "               time.sleep(5)\n",
    "               try:\n",
    "                   driver.find_elements(By.XPATH,'//*[@id=\"JDCol\"]/div/div[2]/button').click()\n",
    "                   print(\"Retry Un click\")\n",
    "               except:\n",
    "                   pass\n",
    "                   \n",
    "               try:\n",
    "                   driver.find_element(By.XPATH,'//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "               except NoSuchElementException:\n",
    "                   pass\n",
    "               collected_successfully = False\n",
    "                              \n",
    "               while not collected_successfully:\n",
    "                   try:\n",
    "                       job_num=job_buttons.index(job_button)\n",
    "                       city=driver.find_element(By.XPATH,'//div[@class=\"css-1v5elnn e11nt52q2\"]').text\n",
    "                       company_name = driver.find_element(By.XPATH,'//div[@class=\"css-87uc0g e1tk4kwz1\"]').text\n",
    "                       location = driver.find_element(By.XPATH,'.//div[@class=\"css-56kyx5 e1tk4kwz5\"]').text\n",
    "                       job_title = driver.find_element(By.XPATH,'.//div[@class=\"css-1vg6q84 e1tk4kwz4\"]').text\n",
    "                       job_id  = job_buttons[job_num].get_attribute(\"data-id\")\n",
    "                       job_url= job_buttons_href[job_num].get_attribute(\"href\")\n",
    "                       collected_successfully = True\n",
    "                   except:\n",
    "                       collected_successfully = True\n",
    "               try:\n",
    "                   Posted_Date=driver.find_element(By.XPATH,'//*[@id=\"MainCol\"]/div[1]/ul/li[{}]/div[2]/div[3]/div[2]/div[2]'.format(job_num+1)).text\n",
    "               except NoSuchElementException:\n",
    "                   try:\n",
    "                       Posted_Date=driver.find_element(By.XPATH,'//*[@id=\"MainCol\"]/div[1]/ul/li[{}]/div[2]/div[2]/div/div[2]'.format(job_num+1)).text\n",
    "                   except:\n",
    "                       Posted_Date=\"N/A\"\n",
    "               now = datetime.now()\n",
    "               try:\n",
    "                   exdate= [int(x) for x in re.findall(r'-?\\d+\\.?\\d*',Posted_Date)][0]\n",
    "                   Posted_Data_N=now.date() - timedelta(days=exdate)\n",
    "               except:\n",
    "                   Posted_Data_N=now.date()\n",
    "                   \n",
    "               #Click on \"Show More\" for extract full description                        \n",
    "               try:\n",
    "                   time.sleep(1)\n",
    "                   driver.find_element(By.XPATH,'//div[@class=\"css-t3xrds e856ufb4\"]').click()\n",
    "                   job_description_full = driver.find_element(By.XPATH,'.//div[@class=\"jobDescriptionContent desc\"]').text \n",
    "                   print(job_description_full)\n",
    "               except NoSuchElementException or StaleElementReferenceException:\n",
    "                   print(job_description_full)\n",
    "                   job_description_full =\"N/A\" \n",
    "                   pass                       \n",
    "               try:\n",
    "                   salary_estimate = driver.find_element(By.XPATH,'//*[@id=\"MainCol\"]/div[1]/ul/li[{}]/div[2]/div[3]/div[1]/span'.format(job_num+1)).text\n",
    "                   \n",
    "               except NoSuchElementException:\n",
    "                   # You need to set a \"not found value. It's important.\"\n",
    "                   salary_estimate = 'N/A'\n",
    "              # print(\"the salary is =\",salary_estimate) \n",
    "               try: \n",
    "                   rating = driver.find_element(By.XPATH,'//*[@id=\"employerStats\"]/div[1]/div[1]').text\n",
    "               except NoSuchElementException:\n",
    "                   # You need to set a \"not found value. It's important.\"\n",
    "                   rating = 'N/A'\n",
    "                   \n",
    "               #Going to the Company Overflow which clicking on this these contains Size, Type , Sector ,Founded ,Industry,Revenue\n",
    "               time.sleep(1)\n",
    "               try:\n",
    "                   driver.find_element(By.XPATH,'//h2[@class=\"mb-std css-1r0ltbv e9b8rvy0\"]').click()\n",
    "                   try:\n",
    "                       size=driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Size\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       size='N/A'\n",
    "                   try:\n",
    "                       type_of_ownership =driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Type\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       type_of_ownership = 'N/A'\n",
    "                   try:\n",
    "                       sector =driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Sector\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       sector = 'N/A'\n",
    "                   try:\n",
    "                       founded =driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Founded\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       founded = 'N/A'\n",
    "                   try:\n",
    "                       industry =driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Industry\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       industry = 'N/A'\n",
    "                   try:\n",
    "                       revenue =driver.find_element(By.XPATH,'.//div[@class=\"d-flex justify-content-start css-rmzuhb e1pvx6aw0\"]//span[text()=\"Revenue\"]//following-sibling::*').text\n",
    "                   except NoSuchElementException:  \n",
    "                       revenue = 'N/A'\n",
    "                  \n",
    "                   \n",
    "               # Rarely, some job postings do not have the \"Company\" tab.   \n",
    "               except NoSuchElementException: \n",
    "                   size='N/A'\n",
    "                   type_of_ownership = 'N/A'\n",
    "                   sector = 'N/A'\n",
    "                   founded = 'N/A'\n",
    "                   industry = 'N/A'\n",
    "                   revenue = 'N/A'\n",
    "                   pass\n",
    "               #Extract Current Date Collection from a Datetime Object\n",
    "               now = datetime.now()\n",
    "               current_date = now.date()\n",
    "               jobs_for_keyword.append({\n",
    "               \n",
    "               \"JobId\" :job_id,\n",
    "               \"City\":city,\n",
    "               \"Source\":\"Glassdoor\",\n",
    "               \"CollectedDate\":current_date,\n",
    "               \"JobTitle\" : job_title,\n",
    "               \"CompanyName\" : company_name,\n",
    "               \"RatingNumber\" : rating,\n",
    "               \"PostedDate\":Posted_Date,\n",
    "               \"Posted_Date_N\":Posted_Data_N,\n",
    "               \"Salary\" : salary_estimate,\n",
    "               \"jobURL\" : job_url,\n",
    "               \"fullJobDescribtion\":job_description_full,\n",
    "               \"Size\":size,\n",
    "               \"Type_Of_Ownership\":type_of_ownership,\n",
    "               \"Sector\":sector,\n",
    "               \"Founded\":founded,\n",
    "               \"Industry\":industry,\n",
    "               \"Revenue\":revenue,\n",
    "               })\n",
    "           # Clicking on the \"next page\" button\n",
    "           try:\n",
    "               page = driver.find_element(By.XPATH,'//*[@id=\"MainCol\"]/div[2]/div/div[2]').text\n",
    "               page = page.split()\n",
    "               if (page[1] == page[3]) or (int(page[1]) == int(page[3])+1):\n",
    "                   print(\"page[1] = \",page[1])\n",
    "                   print(\"page[3] = \",page[3])\n",
    "                   print(\"hhhhh\")\n",
    "                   break\n",
    "               driver.find_element(By.CSS_SELECTOR,'[alt=\"next-icon\"]').click()\n",
    "               time.sleep(5)\n",
    "           except:\n",
    "               print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs_for_country)))\n",
    "               break\n",
    "           \n",
    "                  \n",
    "       #This line converts the dictionary object into a pandas DataFrame.\n",
    "        df= pd.DataFrame(jobs_for_keyword)\n",
    "        print('Type of posting =',keyword[key])\n",
    "        my_conn = create_engine(\"mysql+pymysql://admin:12345678@database-1.ciaff8ckhmlj.us-west-2.rds.amazonaws.com:3306/datafromglassdoor2\")\n",
    "        df.to_sql (con =my_conn , name = 'GlassdoorDataset2' , if_exists = 'append' , index = False )\n",
    "        df.to_excel(\"{}.xlsx\".format(keyword[key]),index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='chromedriver.exe'\n",
    "keyword=['data_scientist','data_engineer','data_entry','data_analyst','data']\n",
    "get_jobs(keyword,500,path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
